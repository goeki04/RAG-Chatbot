services:
  nginx:
    build: .
    image: customopenresty
    container_name: nginx_lb
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf:ro
    environment:
      - AZURE_CLIENT_SECRET=yTu8Q~1ggoRR5s4MoCAaWPAa.wf2kOA2zz_cAbDH
      - NO_PROXY=chatbot,rag_chatbot,vdb_1,vdb_2,localhost,127.0.0.1,172.*,192.168.*
      - no_proxy=chatbot,rag_chatbot,vdb_1,vdb_2,localhost,127.0.0.1,172.*,192.168.*
    depends_on:
      - vdb_1
      - vdb_2
      - chatbot
    networks:
      - qdrant_net

  vdb_1:
    image: qdrant/qdrant:latest
    container_name: vdb_1
    networks:
      - qdrant_net

  vdb_2:
    image: qdrant/qdrant:latest
    container_name: vdb_2
    networks:
      - qdrant_net

  qdrant_loader:
    build:
      context: .
      dockerfile: Dockerfile.loader
    volumes:
      - ./data:/app/data:ro
    environment:
      - NO_PROXY=vdb_1,vdb_2,localhost,127.0.0.1
    networks:
      - qdrant_net
    restart: on-failure

  chatbot:
    image: chatbot
    build:
      dockerfile: Dockerfile.chatbot
    volumes:
      - ./app.py:/app/app.py
      - fastembed_data:/tmp/fastembed_cache
      - ./data/db1:/app/data/db1
      - ./data/db2:/app/data/db2
    command: streamlit run app.py --server.address=0.0.0.0 --server.baseUrlPath=/chat/ --server.fileWatcherType poll
    environment:
      - QDRANT_URL=http://vdb_1:6333
      - COLLECTION_NAME=datenbank_eins
      - OLLAMA_URL=http://host.docker.internal:11434
      - STREAMLIT_SERVER_BASE_PATH=/chat
      - no_proxy=vdb_1,vdb_2,chatbot,localhost,127.0.0.1
    depends_on:
      - vdb_1
    networks:
      - qdrant_net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
volumes:
  fastembed_data:
networks:
  qdrant_net:
    driver: bridge
